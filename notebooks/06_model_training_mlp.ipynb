{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29f0dd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Import MLP model functions\n",
    "from src.models.mlp_regressor import (\n",
    "    load_engineered_data,\n",
    "    prepare_data_for_modeling as prepare_data_regressor,\n",
    "    scale_features,\n",
    "    train_mlp_regressor,\n",
    "    tune_mlp_regressor_hyperparams,\n",
    "    evaluate_regressor,\n",
    "    save_model as save_model_reg,\n",
    "    save_scaler\n",
    ")\n",
    "\n",
    "from src.models.mlp_classifier import (\n",
    "    train_mlp_classifier,\n",
    "    tune_mlp_classifier_hyperparams,\n",
    "    evaluate_classifier,\n",
    "    save_model as save_model_clf,\n",
    "    prepare_data_for_modeling as prepare_data_classifier\n",
    ")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"âœ“ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb81cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload external files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948d3471",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: MLP Regressor - Continuous Delay Prediction\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908713e",
   "metadata": {},
   "source": [
    "### 1.1 Load Engineered Data (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ead6b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset shape: (1519602, 18)\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date (YYYY-MM-DD)</th>\n",
       "      <th>Scheduled Elapsed Time (Minutes)</th>\n",
       "      <th>IsWeekend</th>\n",
       "      <th>Is_Holiday_Period</th>\n",
       "      <th>Carrier_9E</th>\n",
       "      <th>Carrier_AA</th>\n",
       "      <th>Carrier_AS</th>\n",
       "      <th>Carrier_DL</th>\n",
       "      <th>Carrier_EV</th>\n",
       "      <th>Carrier_MQ</th>\n",
       "      <th>Carrier_NK</th>\n",
       "      <th>Carrier_OO</th>\n",
       "      <th>Carrier_UA</th>\n",
       "      <th>Carrier_WN</th>\n",
       "      <th>Carrier_YX</th>\n",
       "      <th>Origin_Airport_Encoded</th>\n",
       "      <th>Season_Encoded</th>\n",
       "      <th>Arrival Delay (Minutes)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>3</td>\n",
       "      <td>-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>-32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date (YYYY-MM-DD)  Scheduled Elapsed Time (Minutes)  IsWeekend  \\\n",
       "0        2019-01-01                                83          0   \n",
       "1        2019-01-01                                72          0   \n",
       "2        2019-01-01                                85          0   \n",
       "3        2019-01-01                               112          0   \n",
       "4        2019-01-01                               129          0   \n",
       "\n",
       "   Is_Holiday_Period  Carrier_9E  Carrier_AA  Carrier_AS  Carrier_DL  \\\n",
       "0                  1           1           0           0           0   \n",
       "1                  1           1           0           0           0   \n",
       "2                  1           1           0           0           0   \n",
       "3                  1           1           0           0           0   \n",
       "4                  1           1           0           0           0   \n",
       "\n",
       "   Carrier_EV  Carrier_MQ  Carrier_NK  Carrier_OO  Carrier_UA  Carrier_WN  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   Carrier_YX  Origin_Airport_Encoded  Season_Encoded  Arrival Delay (Minutes)  \n",
       "0           0                      67               3                       -1  \n",
       "1           0                     163               3                      -14  \n",
       "2           0                      86               3                        9  \n",
       "3           0                      16               3                       -7  \n",
       "4           0                      28               3                      -32  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the regression dataset (outliers removed)\n",
    "input_path_reg = '../data/processed/flight_delays_engineered_regression.csv'\n",
    "df_reg = load_engineered_data(input_path_reg)\n",
    "\n",
    "print(f\"\\nDataset shape: {df_reg.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5f9780d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total features for regression: 16\n",
      "\n",
      "Feature list:\n",
      "   1. Scheduled Elapsed Time (Minutes)\n",
      "   2. IsWeekend\n",
      "   3. Is_Holiday_Period\n",
      "   4. Carrier_9E\n",
      "   5. Carrier_AA\n",
      "   6. Carrier_AS\n",
      "   7. Carrier_DL\n",
      "   8. Carrier_EV\n",
      "   9. Carrier_MQ\n",
      "  10. Carrier_NK\n",
      "  11. Carrier_OO\n",
      "  12. Carrier_UA\n",
      "  13. Carrier_WN\n",
      "  14. Carrier_YX\n",
      "  15. Origin_Airport_Encoded\n",
      "  16. Season_Encoded\n"
     ]
    }
   ],
   "source": [
    "# Define features for modeling\n",
    "exclude_cols_reg = ['Date (YYYY-MM-DD)', 'Carrier Code', 'Origin Airport', \n",
    "                    'Season', 'Arrival Delay (Minutes)', 'Is_Delayed']\n",
    "\n",
    "feature_cols_reg = [col for col in df_reg.columns if col not in exclude_cols_reg]\n",
    "\n",
    "print(f\"\\nTotal features for regression: {len(feature_cols_reg)}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, col in enumerate(feature_cols_reg, 1):\n",
    "    print(f\"  {i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11022f89",
   "metadata": {},
   "source": [
    "### 1.2 Prepare Data & Scale Features (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56fa4fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPARING DATA FOR MLP REGRESSOR\n",
      "============================================================\n",
      "  Training set: 1,215,681 samples\n",
      "  Test set: 303,921 samples\n",
      "  Feature dimensions: 16\n",
      "\n",
      "Target statistics (Training):\n",
      "  Mean: 0.58 minutes\n",
      "  Std:  34.74 minutes\n",
      "  Min:  -60.00 minutes\n",
      "  Max:  300.00 minutes\n",
      "  Training set: 1,215,681 samples\n",
      "  Test set: 303,921 samples\n",
      "  Feature dimensions: 16\n",
      "\n",
      "Target statistics (Training):\n",
      "  Mean: 0.58 minutes\n",
      "  Std:  34.74 minutes\n",
      "  Min:  -60.00 minutes\n",
      "  Max:  300.00 minutes\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "print(\"PREPARING DATA FOR MLP REGRESSOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = prepare_data_regressor(\n",
    "    df_reg, \n",
    "    feature_cols_reg, \n",
    "    'Arrival Delay (Minutes)',\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTarget statistics (Training):\")\n",
    "print(f\"  Mean: {y_train_reg.mean():.2f} minutes\")\n",
    "print(f\"  Std:  {y_train_reg.std():.2f} minutes\")\n",
    "print(f\"  Min:  {y_train_reg.min():.2f} minutes\")\n",
    "print(f\"  Max:  {y_train_reg.max():.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfafcad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SCALING FEATURES\n",
      "  Mean (train): -0.000000\n",
      "  Std Dev (train): 1.000000\n",
      "  âœ“ Features scaled successfully\n",
      "\n",
      "âœ“ Features prepared and scaled for MLP Regressor\n",
      "  Mean (train): -0.000000\n",
      "  Std Dev (train): 1.000000\n",
      "  âœ“ Features scaled successfully\n",
      "\n",
      "âœ“ Features prepared and scaled for MLP Regressor\n"
     ]
    }
   ],
   "source": [
    "# Scale features (CRITICAL for MLP!)\n",
    "X_train_reg_scaled, X_test_reg_scaled, scaler_reg = scale_features(\n",
    "    X_train_reg, \n",
    "    X_test_reg\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Features prepared and scaled for MLP Regressor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6c7a55",
   "metadata": {},
   "source": [
    "### 1.3 Train MLP Regressor (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4802f727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BASELINE MLP REGRESSOR\n",
      "================================================================================\n",
      "TRAINING MLP REGRESSOR\n",
      "\n",
      "Model parameters:\n",
      "  - hidden_layer_sizes: (100, 50)\n",
      "  - activation: relu\n",
      "  - solver: adam\n",
      "  - alpha (L2 penalty): 0.0001\n",
      "  - learning_rate: constant\n",
      "  - learning_rate_init: 0.001\n",
      "  - max_iter: 200\n",
      "  - early_stopping: True\n",
      "  - validation_fraction: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Train baseline MLP regressor\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE MLP REGRESSOR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mlp_reg_baseline = train_mlp_regressor(\n",
    "    X_train_reg_scaled,\n",
    "    y_train_reg,\n",
    "    hidden_layer_sizes=(100, 50),  # 2 hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a314604",
   "metadata": {},
   "source": [
    "### 1.4 Evaluate MLP Regressor (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5b0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline regressor\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE REGRESSOR EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_reg_baseline = evaluate_regressor(\n",
    "    mlp_reg_baseline,\n",
    "    X_train_reg_scaled,\n",
    "    y_train_reg,\n",
    "    X_test_reg_scaled,\n",
    "    y_test_reg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35180155",
   "metadata": {},
   "source": [
    "### 1.5 Hyperparameter Tuning (MLP Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters (this may take several minutes)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING - MLP REGRESSOR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mlp_reg_tuned, best_params_reg = tune_mlp_regressor_hyperparams(\n",
    "    X_train_reg_scaled,\n",
    "    y_train_reg,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8804a3f3",
   "metadata": {},
   "source": [
    "### 1.6 Evaluate Tuned MLP Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0ccbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned regressor\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNED REGRESSOR EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_reg_tuned = evaluate_regressor(\n",
    "    mlp_reg_tuned,\n",
    "    X_train_reg_scaled,\n",
    "    y_train_reg,\n",
    "    X_test_reg_scaled,\n",
    "    y_test_reg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ffaaf2",
   "metadata": {},
   "source": [
    "### 1.7 Compare Baseline vs Tuned (Regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe95e010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"REGRESSOR COMPARISON: BASELINE vs TUNED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_reg = pd.DataFrame({\n",
    "    'Metric': ['RMSE (Test)', 'MAE (Test)', 'RÂ² (Test)', 'RMSE (Train)', 'RÂ² (Train)'],\n",
    "    'Baseline': [\n",
    "        metrics_reg_baseline['test_rmse'],\n",
    "        metrics_reg_baseline['test_mae'],\n",
    "        metrics_reg_baseline['test_r2'],\n",
    "        metrics_reg_baseline['train_rmse'],\n",
    "        metrics_reg_baseline['train_r2']\n",
    "    ],\n",
    "    'Tuned': [\n",
    "        metrics_reg_tuned['test_rmse'],\n",
    "        metrics_reg_tuned['test_mae'],\n",
    "        metrics_reg_tuned['test_r2'],\n",
    "        metrics_reg_tuned['train_rmse'],\n",
    "        metrics_reg_tuned['train_r2']\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_reg['Improvement'] = comparison_reg['Tuned'] - comparison_reg['Baseline']\n",
    "\n",
    "print(\"\\n\", comparison_reg.to_string(index=False))\n",
    "\n",
    "# Determine best model\n",
    "if metrics_reg_tuned['test_rmse'] < metrics_reg_baseline['test_rmse']:\n",
    "    print(\"\\nâœ“ Tuned model performs better!\")\n",
    "    mlp_reg_final = mlp_reg_tuned\n",
    "    metrics_reg_final = metrics_reg_tuned\n",
    "else:\n",
    "    print(\"\\nâœ“ Baseline model performs better!\")\n",
    "    mlp_reg_final = mlp_reg_baseline\n",
    "    metrics_reg_final = metrics_reg_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945e58c",
   "metadata": {},
   "source": [
    "### 1.8 Visualize Regressor Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b3d6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of regressor performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "y_test_pred_reg = metrics_reg_final['y_test_pred']\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0, 0].scatter(y_test_reg, y_test_pred_reg, alpha=0.3, s=10)\n",
    "axes[0, 0].plot([y_test_reg.min(), y_test_reg.max()], \n",
    "                [y_test_reg.min(), y_test_reg.max()], \n",
    "                'r--', lw=2, label='Perfect prediction')\n",
    "axes[0, 0].set_xlabel('Actual Delay (minutes)', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted Delay (minutes)', fontsize=12)\n",
    "axes[0, 0].set_title('MLP Regressor: Actual vs Predicted', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# 2. Residual plot\n",
    "residuals_reg = y_test_reg - y_test_pred_reg\n",
    "axes[0, 1].scatter(y_test_pred_reg, residuals_reg, alpha=0.3, s=10)\n",
    "axes[0, 1].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "axes[0, 1].set_xlabel('Predicted Delay (minutes)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Residuals (minutes)', fontsize=12)\n",
    "axes[0, 1].set_title('Residual Plot', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# 3. Residual distribution\n",
    "axes[1, 0].hist(residuals_reg, bins=100, edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "axes[1, 0].set_xlabel('Residual (minutes)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=12)\n",
    "axes[1, 0].set_title('Residual Distribution', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Error metrics comparison\n",
    "metrics_names = ['RMSE', 'MAE', 'RÂ²']\n",
    "baseline_values = [\n",
    "    metrics_reg_baseline['test_rmse'],\n",
    "    metrics_reg_baseline['test_mae'],\n",
    "    metrics_reg_baseline['test_r2']\n",
    "]\n",
    "tuned_values = [\n",
    "    metrics_reg_tuned['test_rmse'],\n",
    "    metrics_reg_tuned['test_mae'],\n",
    "    metrics_reg_tuned['test_r2']\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 1].bar(x - width/2, baseline_values, width, label='Baseline', alpha=0.8)\n",
    "axes[1, 1].bar(x + width/2, tuned_values, width, label='Tuned', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Metric', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Value', fontsize=12)\n",
    "axes[1, 1].set_title('Model Comparison (Test Set)', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(metrics_names)\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "figures_dir = Path('../results/figures')\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(figures_dir / 'mlp_regressor_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: ../results/figures/mlp_regressor_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf2655",
   "metadata": {},
   "source": [
    "### 1.9 Save MLP Regressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472477a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best regressor model and scaler\n",
    "save_model_reg(mlp_reg_final, '../results/mlp_regressor_model.joblib')\n",
    "save_scaler(scaler_reg, '../results/mlp_regressor_scaler.joblib')\n",
    "\n",
    "print(\"\\nâœ“ MLP Regressor saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf3d272",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: MLP Classifier - Binary Delay Classification\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd02fde",
   "metadata": {},
   "source": [
    "### 2.1 Load Engineered Data (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4127f1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the classification dataset\n",
    "input_path_clf = '../data/processed/flight_delays_engineered.csv'\n",
    "df_clf = load_engineered_data(input_path_clf)\n",
    "\n",
    "print(f\"\\nDataset shape: {df_clf.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df_clf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db439d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for modeling\n",
    "exclude_cols_clf = ['Date (YYYY-MM-DD)', 'Carrier Code', 'Origin Airport', \n",
    "                    'Season', 'Arrival Delay (Minutes)', 'Is_Delayed']\n",
    "\n",
    "feature_cols_clf = [col for col in df_clf.columns if col not in exclude_cols_clf]\n",
    "\n",
    "print(f\"\\nTotal features for classification: {len(feature_cols_clf)}\")\n",
    "print(f\"\\nFeature list:\")\n",
    "for i, col in enumerate(feature_cols_clf, 1):\n",
    "    print(f\"  {i:2}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045aec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS:\")\n",
    "\n",
    "delayed_counts = df_clf['Is_Delayed'].value_counts()\n",
    "delayed_pct = df_clf['Is_Delayed'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nIs_Delayed Distribution:\")\n",
    "print(f\"  Class 0 (On-time):  {delayed_counts[0]:,} ({delayed_pct[0]:.2f}%)\")\n",
    "print(f\"  Class 1 (Delayed):  {delayed_counts[1]:,} ({delayed_pct[1]:.2f}%)\")\n",
    "print(f\"  Imbalance ratio: {delayed_counts[0] / delayed_counts[1]:.2f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbcb9f4",
   "metadata": {},
   "source": [
    "### 2.2 Prepare Data & Scale Features (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data with stratification\n",
    "print(\"PREPARING DATA FOR MLP CLASSIFIER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = prepare_data_classifier(\n",
    "    df_clf,\n",
    "    feature_cols_clf,\n",
    "    'Is_Delayed',\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee61376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features (CRITICAL for MLP!)\n",
    "X_train_clf_scaled, X_test_clf_scaled, scaler_clf = scale_features(\n",
    "    X_train_clf,\n",
    "    X_test_clf\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ“ Features prepared and scaled for MLP Classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa792d8",
   "metadata": {},
   "source": [
    "### 2.3 Train MLP Classifier (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fabb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline MLP classifier\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE MLP CLASSIFIER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mlp_clf_baseline = train_mlp_classifier(\n",
    "    X_train_clf_scaled,\n",
    "    y_train_clf,\n",
    "    hidden_layer_sizes=(100, 50),  # 2 hidden layers\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001,\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=200,\n",
    "    random_state=42,\n",
    "    verbose=False,\n",
    "    early_stopping=True,\n",
    "    validation_fraction=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b8c884",
   "metadata": {},
   "source": [
    "### 2.4 Evaluate MLP Classifier (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c07d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline classifier\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BASELINE CLASSIFIER EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_clf_baseline = evaluate_classifier(\n",
    "    mlp_clf_baseline,\n",
    "    X_train_clf_scaled,\n",
    "    y_train_clf,\n",
    "    X_test_clf_scaled,\n",
    "    y_test_clf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1a6a9a",
   "metadata": {},
   "source": [
    "### 2.5 Hyperparameter Tuning (MLP Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a754bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune hyperparameters (this may take several minutes)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYPERPARAMETER TUNING - MLP CLASSIFIER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "mlp_clf_tuned, best_params_clf = tune_mlp_classifier_hyperparams(\n",
    "    X_train_clf_scaled,\n",
    "    y_train_clf,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8837506e",
   "metadata": {},
   "source": [
    "### 2.6 Evaluate Tuned MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb088ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate tuned classifier\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TUNED CLASSIFIER EVALUATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "metrics_clf_tuned = evaluate_classifier(\n",
    "    mlp_clf_tuned,\n",
    "    X_train_clf_scaled,\n",
    "    y_train_clf,\n",
    "    X_test_clf_scaled,\n",
    "    y_test_clf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019871ee",
   "metadata": {},
   "source": [
    "### 2.7 Compare Baseline vs Tuned (Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9477fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLASSIFIER COMPARISON: BASELINE vs TUNED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_clf = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC'],\n",
    "    'Baseline': [\n",
    "        metrics_clf_baseline['test_accuracy'],\n",
    "        metrics_clf_baseline['test_precision'],\n",
    "        metrics_clf_baseline['test_recall'],\n",
    "        metrics_clf_baseline['test_f1'],\n",
    "        metrics_clf_baseline['test_roc_auc']\n",
    "    ],\n",
    "    'Tuned': [\n",
    "        metrics_clf_tuned['test_accuracy'],\n",
    "        metrics_clf_tuned['test_precision'],\n",
    "        metrics_clf_tuned['test_recall'],\n",
    "        metrics_clf_tuned['test_f1'],\n",
    "        metrics_clf_tuned['test_roc_auc']\n",
    "    ]\n",
    "})\n",
    "\n",
    "comparison_clf['Improvement'] = comparison_clf['Tuned'] - comparison_clf['Baseline']\n",
    "\n",
    "print(\"\\n\", comparison_clf.to_string(index=False))\n",
    "\n",
    "# Determine best model\n",
    "if metrics_clf_tuned['test_f1'] > metrics_clf_baseline['test_f1']:\n",
    "    print(\"\\nâœ“ Tuned model performs better!\")\n",
    "    mlp_clf_final = mlp_clf_tuned\n",
    "    metrics_clf_final = metrics_clf_tuned\n",
    "else:\n",
    "    print(\"\\nâœ“ Baseline model performs better!\")\n",
    "    mlp_clf_final = mlp_clf_baseline\n",
    "    metrics_clf_final = metrics_clf_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0282ed2",
   "metadata": {},
   "source": [
    "### 2.8 Visualize Classifier Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf4285e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of classifier performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Confusion Matrix - Baseline\n",
    "cm_baseline = metrics_clf_baseline['confusion_matrix']\n",
    "disp_baseline = ConfusionMatrixDisplay(confusion_matrix=cm_baseline, \n",
    "                                        display_labels=['On-time', 'Delayed'])\n",
    "disp_baseline.plot(ax=axes[0, 0], cmap='Blues', values_format='d')\n",
    "axes[0, 0].set_title('Confusion Matrix - Baseline', fontweight='bold', fontsize=14)\n",
    "axes[0, 0].grid(False)\n",
    "\n",
    "# 2. Confusion Matrix - Tuned\n",
    "cm_tuned = metrics_clf_tuned['confusion_matrix']\n",
    "disp_tuned = ConfusionMatrixDisplay(confusion_matrix=cm_tuned,\n",
    "                                     display_labels=['On-time', 'Delayed'])\n",
    "disp_tuned.plot(ax=axes[0, 1], cmap='Blues', values_format='d')\n",
    "axes[0, 1].set_title('Confusion Matrix - Tuned', fontweight='bold', fontsize=14)\n",
    "axes[0, 1].grid(False)\n",
    "\n",
    "# 3. ROC Curve comparison\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr_baseline, tpr_baseline, _ = roc_curve(y_test_clf, metrics_clf_baseline['y_test_proba'])\n",
    "fpr_tuned, tpr_tuned, _ = roc_curve(y_test_clf, metrics_clf_tuned['y_test_proba'])\n",
    "\n",
    "axes[1, 0].plot(fpr_baseline, tpr_baseline, label=f\"Baseline (AUC={metrics_clf_baseline['test_roc_auc']:.4f})\", lw=2)\n",
    "axes[1, 0].plot(fpr_tuned, tpr_tuned, label=f\"Tuned (AUC={metrics_clf_tuned['test_roc_auc']:.4f})\", lw=2)\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'k--', lw=2, label='Random Classifier')\n",
    "axes[1, 0].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1, 0].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1, 0].set_title('ROC Curve Comparison', fontweight='bold', fontsize=14)\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# 4. Metrics comparison\n",
    "metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "baseline_values = [\n",
    "    metrics_clf_baseline['test_accuracy'],\n",
    "    metrics_clf_baseline['test_precision'],\n",
    "    metrics_clf_baseline['test_recall'],\n",
    "    metrics_clf_baseline['test_f1'],\n",
    "    metrics_clf_baseline['test_roc_auc']\n",
    "]\n",
    "tuned_values = [\n",
    "    metrics_clf_tuned['test_accuracy'],\n",
    "    metrics_clf_tuned['test_precision'],\n",
    "    metrics_clf_tuned['test_recall'],\n",
    "    metrics_clf_tuned['test_f1'],\n",
    "    metrics_clf_tuned['test_roc_auc']\n",
    "]\n",
    "\n",
    "x = np.arange(len(metrics_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[1, 1].bar(x - width/2, baseline_values, width, label='Baseline', alpha=0.8)\n",
    "axes[1, 1].bar(x + width/2, tuned_values, width, label='Tuned', alpha=0.8)\n",
    "axes[1, 1].set_xlabel('Metric', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Score', fontsize=12)\n",
    "axes[1, 1].set_title('Model Comparison (Test Set)', fontweight='bold', fontsize=14)\n",
    "axes[1, 1].set_xticks(x)\n",
    "axes[1, 1].set_xticklabels(metrics_names, rotation=45, ha='right')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig(figures_dir / 'mlp_classifier_results.png', dpi=300, bbox_inches='tight')\n",
    "print(\"âœ“ Saved: ../results/figures/mlp_classifier_results.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de26557d",
   "metadata": {},
   "source": [
    "### 2.9 Save MLP Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf05f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best classifier model and scaler\n",
    "save_model_clf(mlp_clf_final, '../results/mlp_classifier_model.joblib')\n",
    "save_scaler(scaler_clf, '../results/mlp_classifier_scaler.joblib')\n",
    "\n",
    "print(\"\\nâœ“ MLP Classifier saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f109f1e",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Final Summary & Model Comparison\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17afaaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MLP MODEL TRAINING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š REGRESSOR PERFORMANCE (Test Set):\")\n",
    "print(f\"  RMSE: {metrics_reg_final['test_rmse']:.4f} minutes\")\n",
    "print(f\"  MAE:  {metrics_reg_final['test_mae']:.4f} minutes\")\n",
    "print(f\"  RÂ²:   {metrics_reg_final['test_r2']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ CLASSIFIER PERFORMANCE (Test Set):\")\n",
    "print(f\"  Accuracy:  {metrics_clf_final['test_accuracy']:.4f}\")\n",
    "print(f\"  Precision: {metrics_clf_final['test_precision']:.4f}\")\n",
    "print(f\"  Recall:    {metrics_clf_final['test_recall']:.4f}\")\n",
    "print(f\"  F1-Score:  {metrics_clf_final['test_f1']:.4f}\")\n",
    "print(f\"  ROC-AUC:   {metrics_clf_final['test_roc_auc']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ’¾ SAVED MODELS:\")\n",
    "print(\"  - mlp_regressor_model.joblib\")\n",
    "print(\"  - mlp_regressor_scaler.joblib\")\n",
    "print(\"  - mlp_classifier_model.joblib\")\n",
    "print(\"  - mlp_classifier_scaler.joblib\")\n",
    "\n",
    "print(\"\\nâœ“ MLP model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save performance summary to CSV\n",
    "summary_data = {\n",
    "    'Model': ['MLP Regressor', 'MLP Classifier'],\n",
    "    'Task': ['Regression', 'Binary Classification'],\n",
    "    'Test_RMSE': [metrics_reg_final['test_rmse'], np.nan],\n",
    "    'Test_MAE': [metrics_reg_final['test_mae'], np.nan],\n",
    "    'Test_R2': [metrics_reg_final['test_r2'], np.nan],\n",
    "    'Test_Accuracy': [np.nan, metrics_clf_final['test_accuracy']],\n",
    "    'Test_Precision': [np.nan, metrics_clf_final['test_precision']],\n",
    "    'Test_Recall': [np.nan, metrics_clf_final['test_recall']],\n",
    "    'Test_F1': [np.nan, metrics_clf_final['test_f1']],\n",
    "    'Test_ROC_AUC': [np.nan, metrics_clf_final['test_roc_auc']]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_path = Path('../results/model_performance_summary_mlp.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "print(f\"\\nâœ“ Performance summary saved to: {summary_path}\")\n",
    "print(\"\\n\", summary_df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
